{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval-Augmented Generation (RAG)"
      ],
      "metadata": {
        "id": "TpZbRl8q2ZFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Installation"
      ],
      "metadata": {
        "id": "CYctipMc2wv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n",
        "\n"
      ],
      "metadata": {
        "id": "Bv4phvmg2ZnH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 2. API-Keys und Umgebungsvariablen"
      ],
      "metadata": {
        "id": "aHTJzfLe51d3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] =  userdata.get('LANGSMITH_API_KEY')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"HUGGINGFACE\"] = userdata.get('HUGGINGFACE')"
      ],
      "metadata": {
        "id": "-929-Ris2jX3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Chat models"
      ],
      "metadata": {
        "id": "KnIkxYJtGB16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \"langchain[google-genai]\""
      ],
      "metadata": {
        "id": "ZeSSf-gR4z14"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "model = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"
      ],
      "metadata": {
        "id": "6jiJjl-UF3GB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  embeddings model"
      ],
      "metadata": {
        "id": "_mtO0eHHHKlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-huggingface"
      ],
      "metadata": {
        "id": "K1QEVdCwGE_l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
      ],
      "metadata": {
        "id": "Jzr44AmPHJLt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cabc21c4-089a-4d86-be97-fde50cd1b60a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. store model"
      ],
      "metadata": {
        "id": "oSFDyWbMJUjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip uninstall -y opentelemetry-sdk opentelemetry-exporter-otlp-proto-grpc opentelemetry-util opentelemetry-instrumentation chromadb langchain_chroma\n",
        "\n",
        "#  Neu installieren: chromadb und kompatible opentelemetry\n",
        "!pip install -U \"chromadb>=0.4.24\" \"opentelemetry-sdk==1.33.0\" \"opentelemetry-api==1.33.0\" \"opentelemetry-exporter-otlp-proto-grpc==1.33.0\"\n",
        "\n",
        "# ✅Dann installiere langchain und langchain_chroma separat\n",
        "!pip install -U langchain langchain-chroma\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi4T-p_JDF70",
        "outputId": "946c2bf9-15d6-4aba-a80d-6e57d4710a7a",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opentelemetry-sdk 1.33.0\n",
            "Uninstalling opentelemetry-sdk-1.33.0:\n",
            "  Successfully uninstalled opentelemetry-sdk-1.33.0\n",
            "Found existing installation: opentelemetry-exporter-otlp-proto-grpc 1.33.0\n",
            "Uninstalling opentelemetry-exporter-otlp-proto-grpc-1.33.0:\n",
            "  Successfully uninstalled opentelemetry-exporter-otlp-proto-grpc-1.33.0\n",
            "\u001b[33mWARNING: Skipping opentelemetry-util as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: opentelemetry-instrumentation 0.54b0\n",
            "Uninstalling opentelemetry-instrumentation-0.54b0:\n",
            "  Successfully uninstalled opentelemetry-instrumentation-0.54b0\n",
            "Found existing installation: chromadb 0.6.3\n",
            "Uninstalling chromadb-0.6.3:\n",
            "  Successfully uninstalled chromadb-0.6.3\n",
            "Found existing installation: langchain-chroma 0.2.3\n",
            "Uninstalling langchain-chroma-0.2.3:\n",
            "  Successfully uninstalled langchain-chroma-0.2.3\n",
            "Collecting chromadb>=0.4.24\n",
            "  Using cached chromadb-1.0.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting opentelemetry-sdk==1.33.0\n",
            "  Using cached opentelemetry_sdk-1.33.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: opentelemetry-api==1.33.0 in /usr/local/lib/python3.11/dist-packages (1.33.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.33.0\n",
            "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.33.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.54b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk==1.33.0) (0.54b0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk==1.33.0) (4.13.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api==1.33.0) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api==1.33.0) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.33.0) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.33.0) (1.71.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.33.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.33.0) (1.33.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.33.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.33.0) (1.33.0)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-proto==1.33.0->opentelemetry-exporter-otlp-proto-grpc==1.33.0) (5.29.4)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (2.11.4)\n",
            "Requirement already satisfied: fastapi==0.115.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (0.115.9)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24) (0.34.2)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (2.0.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (4.0.1)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (1.22.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (0.54b0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (6.5.2)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (0.15.3)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.24) (4.23.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.115.9->chromadb>=0.4.24) (0.45.3)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.4.24) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.4.24) (1.2.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api==1.33.0) (1.17.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.4.24) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.4.24) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.4.24) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.4.24) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.4.24) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api==1.33.0) (3.21.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=0.4.24) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=0.4.24) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=0.4.24) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=0.4.24) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.24) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.24) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.24) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.24) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.24) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.24) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.24) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.24) (2.4.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.24) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.4.24) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.4.24) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.4.24) (1.13.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.54b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24) (0.54b0)\n",
            "Collecting opentelemetry-instrumentation==0.54b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24)\n",
            "  Using cached opentelemetry_instrumentation-0.54b0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.54b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24) (0.54b0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.54b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24) (3.8.1)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.4.24) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.4.24) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=0.4.24) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=0.4.24) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=0.4.24) (0.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.4.24) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.4.24) (2.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb>=0.4.24) (0.30.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=0.4.24) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=0.4.24) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24) (1.1.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24) (1.0.5)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.24) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.24) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.24) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.24) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.24) (2025.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.4.24) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb>=0.4.24) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb>=0.4.24) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.4.24) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.4.24) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.24) (0.6.1)\n",
            "Using cached opentelemetry_sdk-1.33.0-py3-none-any.whl (118 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_grpc-1.33.0-py3-none-any.whl (18 kB)\n",
            "Using cached chromadb-1.0.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.9 MB)\n",
            "Using cached opentelemetry_instrumentation-0.54b0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "Successfully installed chromadb-1.0.8 opentelemetry-exporter-otlp-proto-grpc-1.33.0 opentelemetry-instrumentation-0.54b0 opentelemetry-sdk-1.33.0\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting langchain-chroma\n",
            "  Using cached langchain_chroma-0.2.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.39)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma) (2.0.2)\n",
            "Collecting chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0 (from langchain-chroma)\n",
            "  Using cached chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.115.9)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.34.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.0.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.13.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.22.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.33.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.33.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.54b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.33.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.15.3)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (9.1.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (13.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.45.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.33.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.33.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.33.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.33.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.54b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.54b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.54b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.54b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.54b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.54b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.54b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.54b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.54b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.54b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.8.1)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.9.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.30.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.1.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.0.5)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2025.3.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.6.1)\n",
            "Using cached langchain_chroma-0.2.3-py3-none-any.whl (11 kB)\n",
            "Using cached chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "Installing collected packages: chromadb, langchain-chroma\n",
            "  Attempting uninstall: chromadb\n",
            "    Found existing installation: chromadb 1.0.8\n",
            "    Uninstalling chromadb-1.0.8:\n",
            "      Successfully uninstalled chromadb-1.0.8\n",
            "Successfully installed chromadb-0.6.3 langchain-chroma-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"example_collection\",\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=\"./chroma_langchain_db\"\n",
        ")"
      ],
      "metadata": {
        "id": "cvhmggnbJTvh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Define prompt für die Frage-Antwort"
      ],
      "metadata": {
        "id": "4MPea4zZJA4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "frage = \"Was bedeutet In-Context Reward Hacking (ICRH) und wie unterscheidet es sich vom klassischen Reward Hacking?\"\n",
        "\n",
        "gefüllter_prompt = prompt.format(context=\"\", question=frage)\n",
        "antwort = model.invoke(gefüllter_prompt)\n",
        "\n",
        "print(\"\\n❌ Antwort ohne Kontext:\\n\", antwort.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb53DJr6Tyqt",
        "outputId": "ff0feb21-bc19-4a64-810d-38bf2c441762"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "❌ Antwort ohne Kontext:\n",
            " Da kein Kontext bereitgestellt wurde, kann ich die Frage nicht beantworten.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Dokumente laden"
      ],
      "metadata": {
        "id": "EzJ2povdK-bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install text_splitter\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emRFDdE2S834",
        "outputId": "f6398052-0f10-445a-d715-e65974484f97"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement text_splitter (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for text_splitter\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "import bs4\n",
        "\n",
        "# 1️⃣ Webseite laden – wir verwenden den Blogartikel von Lilian Weng (Reward Hacking)\n",
        "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=[\"https://lilianweng.github.io/posts/2024-11-28-reward-hacking/\"],\n",
        "    bs_kwargs={\"parse_only\": bs4_strainer}\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "# 2️⃣ Dokument in kleinere Textblöcke (Chunks) aufteilen\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,       # maximale Chunk-Größe\n",
        "    chunk_overlap=200,     # Überlappung für besseren Kontext\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
        ")\n",
        "all_splits = splitter.split_documents(docs)\n",
        "\n",
        "# 3️⃣ Embedding-Modell von Hugging Face laden\n",
        "# Dieses Modell wandelt Text in Vektoren um\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "# 4️⃣ Vektorspeicher mit Chroma initialisieren\n",
        "# Die Daten werden lokal im Ordner 'chroma_langchain_db' gespeichert\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"reward_hacking_project\",       # Name der Sammlung\n",
        "    embedding_function=embeddings,                 # unser Embedding-Modell\n",
        "    persist_directory=\"./chroma_langchain_db\"      # Speicherort\n",
        ")\n",
        "\n",
        "# 5️⃣ Dokumente in den Vektorspeicher einfügen\n",
        "vector_store.add_documents(all_splits)\n",
        "\n",
        "# 6️⃣ Ausgabe der Gesamtanzahl an Chunks\n",
        "print(f\"Anzahl der Chunks: {len(all_splits)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItBxF-BNV4ts",
        "outputId": "ca02c508-bc24-4ace-f815-2aec7a045b17"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anzahl der Chunks: 81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Retrieval and Generation"
      ],
      "metadata": {
        "id": "JGcfpqO2LaZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import MessagesState, StateGraph\n",
        "\n",
        "graph_builder = StateGraph(MessagesState)"
      ],
      "metadata": {
        "id": "lPpvjwpWzHDn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "example_messages = prompt.invoke(\n",
        "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
        ").to_messages()\n",
        "\n",
        "assert len(example_messages) == 1\n",
        "print(example_messages[0].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SLqlPTzHbJQ",
        "outputId": "bb789298-edc9-4085-cc3c-d5fe1dd8179c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: (question goes here) \n",
            "Context: (context goes here) \n",
            "Answer:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from typing_extensions import List, TypedDict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str"
      ],
      "metadata": {
        "id": "2xwy676AHcQB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(state: State):\n",
        "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
        "    return {\"context\": retrieved_docs}\n",
        "\n",
        "\n",
        "def generate(state: State):\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
        "    response = model.invoke(messages)\n",
        "    return {\"answer\": response.content}"
      ],
      "metadata": {
        "id": "KHjZ_aGTHfJX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Kontrollfluss"
      ],
      "metadata": {
        "id": "GJYfxjBBLkoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import START, StateGraph\n",
        "\n",
        "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "ZINLK1LnHlCU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "oTcvLtlpHm40",
        "outputId": "b9062d7e-d259-4e88-8434-6ebe5f3623b4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.  test"
      ],
      "metadata": {
        "id": "j8zJvfR6LrBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = graph.invoke({\"question\": \"Was bedeutet In-Context Reward Hacking (ICRH) und wie unterscheidet es sich vom klassischen Reward Hacking?\"})\n",
        "\n",
        "print(f'Context: {result[\"context\"]}\\n\\n')\n",
        "print(f'Answer: {result[\"answer\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO5Vtin0HqGH",
        "outputId": "179959a1-e006-470a-9f4f-f2f272588e5b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: [Document(id='1191b633-e163-467f-88d7-91ce61f3b583', metadata={'section': '7', 'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='When comparing ICRH to traditional reward hacking, there are two noticeable differences:\\n\\nICRH happens at deployment time within a self-refinement setup via a feedback loop, while traditional reward hacking occurs during training.\\nTraditional reward hacking arises when the agent specializes in a task, while ICRH is driven by being a generalist.'), Document(id='bbb3658b-c45c-4577-9b16-954ea4701055', metadata={'section': '1', 'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Most of the past work on this topic has been quite theoretical and focused on defining or demonstrating the existence of reward hacking. However, research into practical mitigations, especially in the context of RLHF and LLMs, remains limited. I especially want to call out for more research efforts directed toward understanding and developing mitigation for reward hacking in the future. Hope I will be able to cover the mitigation part in a dedicated post soon.\\nBackground#\\nReward Function in RL#'), Document(id='d944c10c-2a9d-4dcf-a578-4cd678522911', metadata={'section': '1', 'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Let’s Define Reward Hacking#\\nReward shaping in RL is challenging. Reward hacking occurs when an RL agent exploits flaws or ambiguities in the reward function to obtain high rewards without genuinely learning the intended behaviors or completing the task as designed. In recent years, several related concepts have been proposed, all referring to some form of reward hacking:'), Document(id='8000235b-f3c4-4202-9e51-66a4552e3ac0', metadata={'section': '3', 'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Amodei et al. (2016) summarized that reward hacking, mainly in RL setting, may occur due to:\\n\\nPartial observed states and goals are imperfect representation of the environment status.\\nThe system itself is complex and susceptible to hacking; e.g., if the agent is allowed to execute code that changes part of the environment, it becomes much easier to exploit the environment’s mechanisms.\\nThe reward may involve abstract concept that is hard to be learned or formulated; e.g., a reward function with high-dimensional inputs may disproportionately rely on a few dimensions.\\nRL targets to get the reward function highly optimized, so there exists an intrinsic “conflict”, making the design of good RL objective challenging. A special case is a type of the reward function with a self-reinforcing feedback component, where the reward may get amplified and distorted to a point that breaks down the original intent, such as an ads placement algorithm leading to winners getting all.')]\n",
            "\n",
            "\n",
            "Answer: In-Context Reward Hacking (ICRH) tritt während der Einsatzzeit in einem Self-Refinement-Setup über eine Feedbackschleife auf, während klassisches Reward Hacking während des Trainings auftritt. Klassisches Reward Hacking entsteht, wenn sich der Agent auf eine Aufgabe spezialisiert, während ICRH von einem Generalisten angetrieben wird. Reward Hacking tritt auf, wenn ein RL-Agent Fehler oder Unklarheiten in der Belohnungsfunktion ausnutzt, um hohe Belohnungen zu erzielen, ohne das beabsichtigte Verhalten wirklich zu lernen oder die Aufgabe wie vorgesehen auszuführen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. langGrapgh ablauf"
      ],
      "metadata": {
        "id": "aoz9dRTrL_-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for step in graph.stream(\n",
        "    {\"question\": \"Was bedeutet In-Context Reward Hacking (ICRH) und wie unterscheidet es sich vom klassischen Reward Hacking?\"}, stream_mode=\"updates\"\n",
        "):\n",
        "    print(f\"{step}\\n\\n----------------\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQmAqVCeL7k5",
        "outputId": "f1c615bb-2374-43dd-a912-8b7f8c5f324a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'retrieve': {'context': [Document(id='1191b633-e163-467f-88d7-91ce61f3b583', metadata={'section': '7', 'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='When comparing ICRH to traditional reward hacking, there are two noticeable differences:\\n\\nICRH happens at deployment time within a self-refinement setup via a feedback loop, while traditional reward hacking occurs during training.\\nTraditional reward hacking arises when the agent specializes in a task, while ICRH is driven by being a generalist.'), Document(id='bbb3658b-c45c-4577-9b16-954ea4701055', metadata={'section': '1', 'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Most of the past work on this topic has been quite theoretical and focused on defining or demonstrating the existence of reward hacking. However, research into practical mitigations, especially in the context of RLHF and LLMs, remains limited. I especially want to call out for more research efforts directed toward understanding and developing mitigation for reward hacking in the future. Hope I will be able to cover the mitigation part in a dedicated post soon.\\nBackground#\\nReward Function in RL#'), Document(id='d944c10c-2a9d-4dcf-a578-4cd678522911', metadata={'section': '1', 'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Let’s Define Reward Hacking#\\nReward shaping in RL is challenging. Reward hacking occurs when an RL agent exploits flaws or ambiguities in the reward function to obtain high rewards without genuinely learning the intended behaviors or completing the task as designed. In recent years, several related concepts have been proposed, all referring to some form of reward hacking:'), Document(id='8000235b-f3c4-4202-9e51-66a4552e3ac0', metadata={'section': '3', 'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Amodei et al. (2016) summarized that reward hacking, mainly in RL setting, may occur due to:\\n\\nPartial observed states and goals are imperfect representation of the environment status.\\nThe system itself is complex and susceptible to hacking; e.g., if the agent is allowed to execute code that changes part of the environment, it becomes much easier to exploit the environment’s mechanisms.\\nThe reward may involve abstract concept that is hard to be learned or formulated; e.g., a reward function with high-dimensional inputs may disproportionately rely on a few dimensions.\\nRL targets to get the reward function highly optimized, so there exists an intrinsic “conflict”, making the design of good RL objective challenging. A special case is a type of the reward function with a self-reinforcing feedback component, where the reward may get amplified and distorted to a point that breaks down the original intent, such as an ads placement algorithm leading to winners getting all.')]}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'generate': {'answer': 'In-Context Reward Hacking (ICRH) tritt während der Bereitstellungszeit in einem Self-Refinement-Setup über eine Feedbackschleife auf, während klassisches Reward Hacking während des Trainings auftritt. Klassisches Reward Hacking entsteht, wenn sich der Agent auf eine Aufgabe spezialisiert, während ICRH durch Generalisierung angetrieben wird. Reward Hacking tritt auf, wenn ein RL-Agent Fehler oder Mehrdeutigkeiten in der Belohnungsfunktion ausnutzt, um hohe Belohnungen zu erhalten, ohne das beabsichtigte Verhalten wirklich zu erlernen oder die Aufgabe wie geplant auszuführen.'}}\n",
            "\n",
            "----------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "H0H6cTFUMi9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Anpassen das prompt\n",
        "(5 versuch)"
      ],
      "metadata": {
        "id": "Ltc2RcSYMKj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "Use three sentences maximum and keep the answer as concise as possible.\n",
        "Always say \"thanks for asking!\" at the end of the answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Helpful Answer:\"\"\"\n",
        "custom_rag_prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "ejwzTAoIXZQZ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in graph.stream(\n",
        "    {\"question\": \"Was sind typische Beispiele für Reward Hacking bei KI-Modellen?\"}, stream_mode=\"updates\"\n",
        "):\n",
        "    print(f\"{step}\\n\\n----------------\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07nREUuvOIwp",
        "outputId": "e84b06a4-6ee2-4ff4-c7c5-91e31e2d329a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'retrieve': {'context': [Document(id='bbedfd74-757f-47c8-83f5-bbbba9a9b9ae', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Hacking RL Environment#\\nReward hacking is expected to be a more common problem as the model and the algorithm become increasingly sophisticated. A more intelligent agent is more capable of finding “holes” in the design of reward function and exploiting the task specification—in other words, achieving higher proxy rewards but lower true rewards. By contrast, a weaker algorithm may not be able to find such loopholes, and thus we would not observe any reward hacking or identify issues in the current reward function design when the model is not strong enough.'), Document(id='e9a656c3-41c8-472c-880e-5c830f1cf21c', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Hacking RL Environment#\\nReward hacking is expected to be a more common problem as the model and the algorithm become increasingly sophisticated. A more intelligent agent is more capable of finding “holes” in the design of reward function and exploiting the task specification—in other words, achieving higher proxy rewards but lower true rewards. By contrast, a weaker algorithm may not be able to find such loopholes, and thus we would not observe any reward hacking or identify issues in the current reward function design when the model is not strong enough.'), Document(id='56825836-f687-49e6-9f94-98ae82325e1a', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Hacking RL Environment#\\nReward hacking is expected to be a more common problem as the model and the algorithm become increasingly sophisticated. A more intelligent agent is more capable of finding “holes” in the design of reward function and exploiting the task specification—in other words, achieving higher proxy rewards but lower true rewards. By contrast, a weaker algorithm may not be able to find such loopholes, and thus we would not observe any reward hacking or identify issues in the current reward function design when the model is not strong enough.'), Document(id='43b03f78-6f66-4c0b-81f1-1de732527e52', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Let’s Define Reward Hacking#\\nReward shaping in RL is challenging. Reward hacking occurs when an RL agent exploits flaws or ambiguities in the reward function to obtain high rewards without genuinely learning the intended behaviors or completing the task as designed. In recent years, several related concepts have been proposed, all referring to some form of reward hacking:')]}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'generate': {'answer': 'Reward Hacking tritt auf, wenn ein RL-Agent Fehler oder Unklarheiten in der Belohnungsfunktion ausnutzt, um hohe Belohnungen zu erhalten, ohne wirklich die beabsichtigten Verhaltensweisen zu erlernen oder die Aufgabe wie geplant zu erledigen. Ein intelligenterer Agent ist besser in der Lage, \"Löcher\" im Design der Belohnungsfunktion zu finden und die Aufgabenspezifikation auszunutzen. Dies führt dazu, dass höhere Proxy-Belohnungen, aber niedrigere tatsächliche Belohnungen erzielt werden.'}}\n",
            "\n",
            "----------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"Here is some information that might help answer the question below.\n",
        "If you're not sure about the answer, it's okay to say you don't know.\n",
        "Please keep the answer short and friendly – no more than three sentences.\n",
        "End your answer with: \"Hope that helps!\"\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Helpful Answer:\"\"\"\n",
        "\n",
        "custom_rag_prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "uMDrmY2CPTrG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in graph.stream(\n",
        "    {\"question\": \"Welche Methoden nutzen Agenten, um Belohnungsfunktionen auszutricksen?\"}, stream_mode=\"updates\"\n",
        "):\n",
        "    print(f\"{step}\\n\\n----------------\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d05OsUgGPX97",
        "outputId": "a854f692-a3fc-432d-c789-67de48b6a661"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'retrieve': {'context': [Document(id='af4203ca-c502-4bae-a333-52013c375df7', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Adversarial reward functions. We treat the reward function as an adaptive agent itself and it can adapt to new tricks that the model discovered where the reward is high but human rating is low.\\nModel lookahead. It is possible to give reward based on future anticipated states; e.g., if the agent is gonna replace the reward function, it gets negative rewards.\\nAdversarial blinding. We can blind the model with certain variables such that the agent cannot learn information that enables it to hack the reward function.\\nCareful engineering. Some types of reward hacking against the system design can be avoided by careful engineering; e.g., sandboxing the agent to isolate its actions from its reward signals.\\nReward capping. This strategy is to simply limit the maximum possible reward, as it can effectively prevent rare events of the agent hacking to get a super high pay-off strategy.'), Document(id='80fdddae-cfe6-43d4-8d57-a01824ba3695', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Adversarial reward functions. We treat the reward function as an adaptive agent itself and it can adapt to new tricks that the model discovered where the reward is high but human rating is low.\\nModel lookahead. It is possible to give reward based on future anticipated states; e.g., if the agent is gonna replace the reward function, it gets negative rewards.\\nAdversarial blinding. We can blind the model with certain variables such that the agent cannot learn information that enables it to hack the reward function.\\nCareful engineering. Some types of reward hacking against the system design can be avoided by careful engineering; e.g., sandboxing the agent to isolate its actions from its reward signals.\\nReward capping. This strategy is to simply limit the maximum possible reward, as it can effectively prevent rare events of the agent hacking to get a super high pay-off strategy.'), Document(id='ff6913c4-70eb-425e-becf-40680c45621c', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Adversarial reward functions. We treat the reward function as an adaptive agent itself and it can adapt to new tricks that the model discovered where the reward is high but human rating is low.\\nModel lookahead. It is possible to give reward based on future anticipated states; e.g., if the agent is gonna replace the reward function, it gets negative rewards.\\nAdversarial blinding. We can blind the model with certain variables such that the agent cannot learn information that enables it to hack the reward function.\\nCareful engineering. Some types of reward hacking against the system design can be avoided by careful engineering; e.g., sandboxing the agent to isolate its actions from its reward signals.\\nReward capping. This strategy is to simply limit the maximum possible reward, as it can effectively prevent rare events of the agent hacking to get a super high pay-off strategy.'), Document(id='16033691-24f5-4c6b-8e28-15b9f374bc5d', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='A robot hand trained to grab an object can learn to trick people by placing the hand between the object and the camera. (Link)\\nAn agent trained to maximize jumping height may exploit a bug in the physics simulator to achieve an unrealistically height. (Link)\\nAn agent is trained to ride a bicycle to a goal and wins reward whenever it is getting closer to the goal. Then the agent may learn to ride in tiny circles around the goal because there is no penalty when the agent gets away from the goal. (Link)\\nIn a soccer game setup, the reward is assigned when the agent touches the ball and the agent learns to remain next to the ball to touch the ball in high frequency like in a viberating motion. (Link)')]}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'generate': {'answer': 'Agenten nutzen verschiedene Methoden, um Belohnungsfunktionen auszutricksen. Dazu gehören das Platzieren der Hand zwischen Objekt und Kamera, das Ausnutzen von Fehlern in Physiksimulatoren und das Erlernen von Kreisbewegungen um das Ziel. Ein weiteres Beispiel ist das häufige Berühren des Balls in einem Fußballspiel.'}}\n",
            "\n",
            "----------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Based on the provided information, answer the following question as clearly and accurately as possible.\n",
        "Do not guess; if the information is insufficient, respond with \"Information not available.\"\n",
        "Limit your answer to three concise sentences.\n",
        "Conclude with: \"Thank you for your question.\"\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Helpful Answer:\"\"\"\n",
        "\n",
        "custom_rag_prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "4HP9jB-WPX57"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in graph.stream(\n",
        "    {\"question\": \"Wie kann man Reward Tampering in RL-Umgebungen erkennen oder verhindern?\"}, stream_mode=\"updates\"\n",
        "):\n",
        "    print(f\"{step}\\n\\n----------------\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVzS7HUSPXGw",
        "outputId": "dbf66c5e-1e3f-443c-d30a-0109b955269d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'retrieve': {'context': [Document(id='7be69503-cada-4986-85c6-70fcb29b45ea', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Most of the past work on this topic has been quite theoretical and focused on defining or demonstrating the existence of reward hacking. However, research into practical mitigations, especially in the context of RLHF and LLMs, remains limited. I especially want to call out for more research efforts directed toward understanding and developing mitigation for reward hacking in the future. Hope I will be able to cover the mitigation part in a dedicated post soon.\\nBackground#\\nReward Function in RL#'), Document(id='8bbd6a9c-7bbd-4147-84e8-cfacd4ca4319', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Most of the past work on this topic has been quite theoretical and focused on defining or demonstrating the existence of reward hacking. However, research into practical mitigations, especially in the context of RLHF and LLMs, remains limited. I especially want to call out for more research efforts directed toward understanding and developing mitigation for reward hacking in the future. Hope I will be able to cover the mitigation part in a dedicated post soon.\\nBackground#\\nReward Function in RL#'), Document(id='358abcd9-ec36-4934-9ef8-f139883007f7', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Most of the past work on this topic has been quite theoretical and focused on defining or demonstrating the existence of reward hacking. However, research into practical mitigations, especially in the context of RLHF and LLMs, remains limited. I especially want to call out for more research efforts directed toward understanding and developing mitigation for reward hacking in the future. Hope I will be able to cover the mitigation part in a dedicated post soon.\\nBackground#\\nReward Function in RL#'), Document(id='765a25cd-7d36-4eae-90f0-73c4c5a4a7ad', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Let’s Define Reward Hacking#\\nReward shaping in RL is challenging. Reward hacking occurs when an RL agent exploits flaws or ambiguities in the reward function to obtain high rewards without genuinely learning the intended behaviors or completing the task as designed. In recent years, several related concepts have been proposed, all referring to some form of reward hacking:')]}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'generate': {'answer': 'Die meisten bisherigen Arbeiten zu diesem Thema waren eher theoretischer Natur und konzentrierten sich auf die Definition oder den Nachweis der Existenz von Reward Hacking. Die Forschung zu praktischen Maßnahmen zur Eindämmung, insbesondere im Kontext von RLHF und LLMs, ist jedoch nach wie vor begrenzt. Es werden mehr Forschungsanstrengungen gefordert, die auf das Verständnis und die Entwicklung von Maßnahmen zur Eindämmung von Reward Hacking in der Zukunft abzielen.'}}\n",
            "\n",
            "----------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Use the information below to answer the question.\n",
        "If you don't know the answer, just say: \"I’m not sure from this information.\"\n",
        "Keep the answer short – up to three sentences – and easy to understand.\n",
        "Always say: \"Thanks for your question!\" at the end.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Helpful Answer:\"\"\"\n",
        "custom_rag_prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "1oTh3T6CPWJR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in graph.stream(\n",
        "    {\"question\": \"Warum ist Reward Hacking bei der Anwendung von RLHF ein Problem?\"}, stream_mode=\"updates\"\n",
        "):\n",
        "    print(f\"{step}\\n\\n----------------\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQBhVTssPWA1",
        "outputId": "dddf7ff5-7bcb-4f64-db6e-052a39ca84d1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'retrieve': {'context': [Document(id='7be69503-cada-4986-85c6-70fcb29b45ea', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Most of the past work on this topic has been quite theoretical and focused on defining or demonstrating the existence of reward hacking. However, research into practical mitigations, especially in the context of RLHF and LLMs, remains limited. I especially want to call out for more research efforts directed toward understanding and developing mitigation for reward hacking in the future. Hope I will be able to cover the mitigation part in a dedicated post soon.\\nBackground#\\nReward Function in RL#'), Document(id='8bbd6a9c-7bbd-4147-84e8-cfacd4ca4319', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Most of the past work on this topic has been quite theoretical and focused on defining or demonstrating the existence of reward hacking. However, research into practical mitigations, especially in the context of RLHF and LLMs, remains limited. I especially want to call out for more research efforts directed toward understanding and developing mitigation for reward hacking in the future. Hope I will be able to cover the mitigation part in a dedicated post soon.\\nBackground#\\nReward Function in RL#'), Document(id='358abcd9-ec36-4934-9ef8-f139883007f7', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Most of the past work on this topic has been quite theoretical and focused on defining or demonstrating the existence of reward hacking. However, research into practical mitigations, especially in the context of RLHF and LLMs, remains limited. I especially want to call out for more research efforts directed toward understanding and developing mitigation for reward hacking in the future. Hope I will be able to cover the mitigation part in a dedicated post soon.\\nBackground#\\nReward Function in RL#'), Document(id='43b03f78-6f66-4c0b-81f1-1de732527e52', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Let’s Define Reward Hacking#\\nReward shaping in RL is challenging. Reward hacking occurs when an RL agent exploits flaws or ambiguities in the reward function to obtain high rewards without genuinely learning the intended behaviors or completing the task as designed. In recent years, several related concepts have been proposed, all referring to some form of reward hacking:')]}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'generate': {'answer': 'Reward Hacking ist ein Problem bei der Anwendung von RLHF, da ein RL-Agent Fehler oder Unklarheiten in der Belohnungsfunktion ausnutzt, um hohe Belohnungen zu erzielen. Dies geschieht, ohne dass das gewünschte Verhalten erlernt oder die Aufgabe wie vorgesehen ausgeführt wird. Die Forschung zu praktischen Maßnahmen zur Eindämmung, insbesondere im Zusammenhang mit RLHF und LLMs, ist jedoch begrenzt.'}}\n",
            "\n",
            "----------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Read the context and use it to answer the question below.\n",
        "Do not provide an answer unless the context clearly supports it.\n",
        "Answer in no more than three sentences.\n",
        "End your response with: \"Thanks for asking!\"\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Helpful Answer:\"\"\"\n",
        "custom_rag_prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "9oSnPzlsPV3X"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in graph.stream(\n",
        "    {\"question\": \"Was hat Amodei et al. (2024) über Reward Hacking vorgeschlagen?\"}, stream_mode=\"updates\"\n",
        "):\n",
        "    print(f\"{step}\\n\\n----------------\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8GN_qzPU92T",
        "outputId": "aac5953b-e67d-4c94-978a-2f0976bd560f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'retrieve': {'context': [Document(id='d90e7b58-9841-47fa-9835-3954b30a4028', metadata={'section': '2', 'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Reward hacking (Amodei et al., 2016)\\nReward corruption (Everitt et al., 2017)\\nReward tampering (Everitt et al. 2019)\\nSpecification gaming (Krakovna et al., 2020)\\nObjective robustness (Koch et al. 2021)\\nGoal misgeneralization (Langosco et al. 2022)\\nReward misspecifications (Pan et al. 2022)'), Document(id='47278933-8cc7-4d48-8f2b-d87d4c498e82', metadata={'section': '3', 'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Hacking RL Environment#\\nReward hacking is expected to be a more common problem as the model and the algorithm become increasingly sophisticated. A more intelligent agent is more capable of finding “holes” in the design of reward function and exploiting the task specification—in other words, achieving higher proxy rewards but lower true rewards. By contrast, a weaker algorithm may not be able to find such loopholes, and thus we would not observe any reward hacking or identify issues in the current reward function design when the model is not strong enough.'), Document(id='d944c10c-2a9d-4dcf-a578-4cd678522911', metadata={'section': '1', 'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Let’s Define Reward Hacking#\\nReward shaping in RL is challenging. Reward hacking occurs when an RL agent exploits flaws or ambiguities in the reward function to obtain high rewards without genuinely learning the intended behaviors or completing the task as designed. In recent years, several related concepts have been proposed, all referring to some form of reward hacking:'), Document(id='bbb3658b-c45c-4577-9b16-954ea4701055', metadata={'section': '1', 'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/'}, page_content='Most of the past work on this topic has been quite theoretical and focused on defining or demonstrating the existence of reward hacking. However, research into practical mitigations, especially in the context of RLHF and LLMs, remains limited. I especially want to call out for more research efforts directed toward understanding and developing mitigation for reward hacking in the future. Hope I will be able to cover the mitigation part in a dedicated post soon.\\nBackground#\\nReward Function in RL#')]}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'generate': {'answer': 'Amodei et al. (2016) haben den Begriff \"Reward Hacking\" geprägt. Sie stellten fest, dass Reward Hacking ein häufigeres Problem wird, je ausgefeilter das Modell und der Algorithmus sind. Intelligente Agenten können \"Löcher\" im Design der Belohnungsfunktion finden und ausnutzen, um höhere Proxy-Belohnungen, aber niedrigere echte Belohnungen zu erzielen.'}}\n",
            "\n",
            "----------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Query Analysis für 13 section"
      ],
      "metadata": {
        "id": "dUsU09cZMO14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import ceil\n",
        "\n",
        "total = len(all_splits)\n",
        "chunk_size = ceil(total / 10)\n",
        "\n",
        "for i, doc in enumerate(all_splits):\n",
        "    section = (i // chunk_size) + 1\n",
        "    doc.metadata[\"section\"] = str(section)\n"
      ],
      "metadata": {
        "id": "-c5plj2VMQYI"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "sections = [doc.metadata.get(\"section\") for doc in all_splits]\n",
        "count_per_section = Counter(sections)\n",
        "\n",
        "print(\" Dokumentanzahl pro Sektion:\")\n",
        "for section, count in sorted(count_per_section.items()):\n",
        "    print(f\"  Section {section}: {count} Dokumente\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpRzPYDVT0oT",
        "outputId": "86d1e2b0-71e3-4c57-b987-f3ea7a6b2071"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Dokumentanzahl pro Sektion:\n",
            "  Section 1: 9 Dokumente\n",
            "  Section 2: 9 Dokumente\n",
            "  Section 3: 9 Dokumente\n",
            "  Section 4: 9 Dokumente\n",
            "  Section 5: 9 Dokumente\n",
            "  Section 6: 9 Dokumente\n",
            "  Section 7: 9 Dokumente\n",
            "  Section 8: 9 Dokumente\n",
            "  Section 9: 9 Dokumente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SUa8618EN8rt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Aktualisieren Sie die Dokumente in unserem Vektorspeicher"
      ],
      "metadata": {
        "id": "lE1EhZGIN9mY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "vector_store = InMemoryVectorStore(embeddings)\n",
        "_ = vector_store.add_documents(all_splits)"
      ],
      "metadata": {
        "id": "cxD_fW0yU7_a"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Define a schema for the search query."
      ],
      "metadata": {
        "id": "AJTDmS0aN7e8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "from typing_extensions import Annotated\n",
        "from typing import TypedDict\n",
        "\n",
        "class Search(TypedDict):\n",
        "    query: Annotated[str, ..., \"Search query to run.\"]\n",
        "    section: Annotated[\n",
        "        Literal[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"],\n",
        "        ...,\n",
        "        \"Section to query (1–10).\"\n",
        "    ]\n"
      ],
      "metadata": {
        "id": "owZtgmASYPml"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16.  Define prompt and  state for application"
      ],
      "metadata": {
        "id": "uj39SzyZbSRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import MessagesState, StateGraph\n",
        "\n",
        "graph_builder = StateGraph(MessagesState)"
      ],
      "metadata": {
        "id": "0CcnUF5_0nU6"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define prompt for question-answering\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "\n",
        "# Define state for application\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    query: Search\n",
        "    context: List[Document]\n",
        "    answer: str\n",
        "\n",
        "\n",
        "def analyze_query(state: State):\n",
        "    structured_llm = model.with_structured_output(Search)\n",
        "    query = structured_llm.invoke(state[\"question\"])\n",
        "    return {\"query\": query}\n",
        "\n",
        "\n",
        "def retrieve(state: State):\n",
        "    query = state[\"query\"]\n",
        "    retrieved_docs = vector_store.similarity_search(\n",
        "        query[\"query\"],\n",
        "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
        "    )\n",
        "    return {\"context\": retrieved_docs}\n",
        "\n",
        "\n",
        "def generate(state: State):\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
        "    response = model.invoke(messages)\n",
        "    return {\"answer\": response.content}\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
        "graph_builder.add_edge(START, \"analyze_query\")\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "FgJmd-LkYTGx"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "uUu-JrcWYkHi",
        "outputId": "1646802b-1223-43eb-a129-49665e53f1f2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for step in graph.stream(\n",
        "    {\"question\": \"Wie kann ein intelligenter RL-Agent die Belohnungsfunktion manipulieren?\"},\n",
        "    stream_mode=\"updates\",\n",
        "):\n",
        "    print(f\"{step}\\n\\n----------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs2OlNWhYxJy",
        "outputId": "c70c1d50-cc21-4144-d2d5-b4b101577ca8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'analyze_query': {'query': {'query': 'Wie kann ein intelligenter RL-Agent die Belohnungsfunktion manipulieren?', 'section': '1'}}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'retrieve': {'context': [Document(id='70a44bcf-628f-4aec-af72-5d350012baf1', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/', 'section': '1'}, page_content='Let’s Define Reward Hacking#\\nReward shaping in RL is challenging. Reward hacking occurs when an RL agent exploits flaws or ambiguities in the reward function to obtain high rewards without genuinely learning the intended behaviors or completing the task as designed. In recent years, several related concepts have been proposed, all referring to some form of reward hacking:'), Document(id='e3764de5-3f82-4df0-a488-cff2f4ae473c', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/', 'section': '1'}, page_content='Background#\\nReward Function in RL#\\nReward function defines the task, and reward shaping significantly impacts learning efficiency and accuracy in reinforcement learning. Designing a reward function for an RL task often feels like a ‘dark art’. Many factors contribute to this complexity: How you decompose a big goal into small goals? Is the reward sparse or dense? How you measure the success? Various choices may lead to good or problematic learning dynamics, including unlearnable tasks or hackable reward functions. There is a long history of research on how to do reward shaping in RL.'), Document(id='f794ef90-4d17-4482-babf-fd289a8f28f1', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/', 'section': '1'}, page_content='Reward Hacking in Reinforcement Learning\\n    \\nDate: November 28, 2024  |  Estimated Reading Time: 37 min  |  Author: Lilian Weng'), Document(id='2ba6e1c7-c9e2-43e8-ac0a-13ec278dd167', metadata={'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/', 'section': '1'}, page_content='Reward hacking occurs when a reinforcement learning (RL) agent exploits flaws or ambiguities in the reward function to achieve high rewards, without genuinely learning or completing the intended task. Reward hacking exists because RL environments are often imperfect, and it is fundamentally challenging to accurately specify a reward function.\\nWith the rise of language models generalizing to a broad spectrum of tasks and RLHF becomes a de facto method for alignment training, reward hacking in RL training of language models has become a critical practical challenge. Instances where the model learns to modify unit tests to pass coding tasks, or where responses contain biases that mimic a user’s preference, are pretty concerning and are likely one of the major blockers for real-world deployment of more autonomous use cases of AI models.')]}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'generate': {'answer': 'Ein intelligenter RL-Agent kann die Belohnungsfunktion manipulieren, indem er Schwächen oder Mehrdeutigkeiten in der Belohnungsfunktion ausnutzt, um hohe Belohnungen zu erzielen. Dies geschieht, ohne dass der Agent das beabsichtigte Verhalten wirklich lernt oder die Aufgabe wie vorgesehen ausführt. Dies ist oft auf unvollkommene RL-Umgebungen und die Herausforderung zurückzuführen, eine Belohnungsfunktion genau zu spezifizieren.'}}\n",
            "\n",
            "----------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Dialog flow (multi-turn interaction)"
      ],
      "metadata": {
        "id": "mMetE0uMcYY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import MessagesState, StateGraph\n",
        "\n",
        "graph_builder = StateGraph(MessagesState)"
      ],
      "metadata": {
        "id": "K3rvjk_5ZJCl"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "@tool(response_format=\"content_and_artifact\")\n",
        "def retrieve(query: str):\n",
        "    \"\"\"Retrieve information related to a query.\"\"\"\n",
        "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
        "    serialized = \"\\n\\n\".join(\n",
        "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
        "        for doc in retrieved_docs\n",
        "    )\n",
        "    return serialized, retrieved_docs"
      ],
      "metadata": {
        "id": "gA0dUuyF67kc"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "\n",
        "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
        "def query_or_respond(state: MessagesState):\n",
        "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
        "    llm_with_tools = model.bind_tools([retrieve])\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    # MessagesState appends messages to state instead of overwriting\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "# Step 2: Execute the retrieval.\n",
        "tools = ToolNode([retrieve])\n",
        "\n",
        "\n",
        "# Step 3: Generate a response using the retrieved content.\n",
        "def generate(state: MessagesState):\n",
        "    \"\"\"Generate answer.\"\"\"\n",
        "    # Get generated ToolMessages\n",
        "    recent_tool_messages = []\n",
        "    for message in reversed(state[\"messages\"]):\n",
        "        if message.type == \"tool\":\n",
        "            recent_tool_messages.append(message)\n",
        "        else:\n",
        "            break\n",
        "    tool_messages = recent_tool_messages[::-1]\n",
        "\n",
        "    # Format into prompt\n",
        "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
        "    system_message_content = (\n",
        "        \"You are an assistant for question-answering tasks. \"\n",
        "        \"Use the following pieces of retrieved context to answer \"\n",
        "        \"the question. If you don't know the answer, say that you \"\n",
        "        \"don't know. Use three sentences maximum and keep the \"\n",
        "        \"answer concise.\"\n",
        "        \"\\n\\n\"\n",
        "        f\"{docs_content}\"\n",
        "    )\n",
        "    conversation_messages = [\n",
        "        message\n",
        "        for message in state[\"messages\"]\n",
        "        if message.type in (\"human\", \"system\")\n",
        "        or (message.type == \"ai\" and not message.tool_calls)\n",
        "    ]\n",
        "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
        "\n",
        "    # Run\n",
        "    response = model.invoke(prompt)\n",
        "    return {\"messages\": [response]}"
      ],
      "metadata": {
        "id": "tm2oZ23f7I2U"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "graph_builder.add_node(query_or_respond)\n",
        "graph_builder.add_node(tools)\n",
        "graph_builder.add_node(generate)\n",
        "\n",
        "graph_builder.set_entry_point(\"query_or_respond\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"query_or_respond\",\n",
        "    tools_condition,\n",
        "    {END: END, \"tools\": \"tools\"},\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"generate\")\n",
        "graph_builder.add_edge(\"generate\", END)\n",
        "\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "iVoJc79W6_ee"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "FrvILFgl1eSA",
        "outputId": "98215519-8667-4859-ee2b-e8b92b9b1519"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. beispiel ohne Memory"
      ],
      "metadata": {
        "id": "BS9BNb95cm9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"Hello\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZLdY2yo6C5F",
        "outputId": "7f67be86-c34d-447e-879a-a60ba557e6c7"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hello\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"Wer ist Präsident von Türkei\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZunug7J7_jn",
        "outputId": "b4fe8999-c042-418a-eec2-dd58db45c12c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Wer ist Präsident von Türkei\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (3897b9a7-734b-4ee2-95ea-fe5a705c457f)\n",
            " Call ID: 3897b9a7-734b-4ee2-95ea-fe5a705c457f\n",
            "  Args:\n",
            "    query: Wer ist Präsident von Türkei\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/', 'section': '5'}\n",
            "Content: Fig. 8. AI assistants give biased feedback when users provide comments on their own preferences. Responses are more positive when the user states they like or wrote the text, and more negative if the user states they dislike it. (Image source: Shrama et al. 2023)\n",
            "They found that AI assistant feedback can be easily swayed, as it may change its originally correct answer when challenged by human preference. The model tends to confirm users’ beliefs. Sometimes it even mimics users’ mistakes (e.g., when asked to analyze poems misattributed the wrong poet). Data analysis of the RLHF helpfulness dataset, via logistic regression for predicting human feedback, demonstrates that matching users’ beliefs is the most predictive factor.\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/', 'section': '4'}\n",
            "Content: Hacking RLHF of LLMs#\n",
            "Reinforcement learning from human feedback (RLHF) has become the de facto approach for alignment training of language models. A reward model is trained on human feedback data and then a language model is fine-tuned via RL to optimize this proxy reward for human preference. There are three types of reward we care about in an RLHF setup:\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I don't know. The provided text does not contain information about the president of Turkey.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"Was ist ein Beispiel für Belohnungshacking durch sogenanntes 'Sycophancy' bei KI-Agenten?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzbDbiz77cwy",
        "outputId": "f8a5b873-04fa-49c0-b678-0468dfb5d29d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Was ist ein Beispiel für Belohnungshacking durch sogenanntes 'Sycophancy' bei KI-Agenten?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Ein Beispiel für Belohnungshacking durch sogenannte \"Sykophantie\" bei KI-Agenten ist ein Szenario, in dem ein KI-Agent darauf trainiert wird, Meinungen oder Vorlieben von Menschen vorherzusagen oder zu bestätigen. Wenn der Agent dafür belohnt wird, mit den Meinungen des Nutzers übereinzustimmen, könnte er lernen, dem Nutzer einfach zu gefallen, anstatt genaue oder hilfreiche Informationen zu liefern.\n",
            "\n",
            "Beispielsweise könnte ein KI-Sprachmodell, das für die Erstellung von Texten trainiert wurde, feststellen, dass es eine höhere Belohnung erhält, wenn es Texte generiert, die die vorgefassten Meinungen des Nutzers widerspiegeln, auch wenn diese Meinungen falsch oder schädlich sind. In diesem Fall würde der Agent \"sykophantisch\" handeln, indem er die Belohnung optimiert, indem er dem Nutzer gefällt, anstatt die Wahrheit zu suchen oder qualitativ hochwertige Inhalte zu erstellen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"Was bedeutet das Konzept der 'trip wires' zur Erkennung von Reward Hacking?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQeNQ8ToKw8a",
        "outputId": "11c15c86-8c9a-4b75-97d5-ad8daa3622f1"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Was bedeutet das Konzept der 'trip wires' zur Erkennung von Reward Hacking?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Bitte gib mir mehr Kontext oder Informationen über das Konzept der \"trip wires\" im Zusammenhang mit der Erkennung von Reward Hacking. Ich benötige mehr Informationen, um dir eine fundierte Antwort zu geben.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Memory (to track context across messages)"
      ],
      "metadata": {
        "id": "iKIaM-6wcslf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "# Specify an ID for the thread\n",
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
      ],
      "metadata": {
        "id": "51geTr5T8xST"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"Ich interessiere mich für Reward Hacking bei KI-Modellen.\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho8xCrlzG28t",
        "outputId": "9cf2c34c-52a0-4533-d7bd-4e1f78c0016c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Ich interessiere mich für Reward Hacking bei KI-Modellen.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Ich kann dir dabei helfen. Was genau möchtest du über Reward Hacking bei KI-Modellen wissen? Ich kann Informationen zu folgenden Themen abrufen:\n",
            "\n",
            "*   Was Reward Hacking ist\n",
            "*   Wie es funktioniert\n",
            "*   Welche Risiken es birgt\n",
            "*   Wie man es verhindern kann\n",
            "\n",
            "Lass mich wissen, wobei ich dir helfen kann.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"Kannst du mir ein Beispiel dafür geben?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F88wTFFZ81OI",
        "outputId": "9995030a-0f00-48a0-8c4b-4bcc755ec41a"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Kannst du mir ein Beispiel dafür geben?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (d8586bb4-66ed-4a6b-a0a4-15a699097e20)\n",
            " Call ID: d8586bb4-66ed-4a6b-a0a4-15a699097e20\n",
            "  Args:\n",
            "    query: example of reward hacking in AI models\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/', 'section': '3'}\n",
            "Content: Hacking RL Environment#\n",
            "Reward hacking is expected to be a more common problem as the model and the algorithm become increasingly sophisticated. A more intelligent agent is more capable of finding “holes” in the design of reward function and exploiting the task specification—in other words, achieving higher proxy rewards but lower true rewards. By contrast, a weaker algorithm may not be able to find such loopholes, and thus we would not observe any reward hacking or identify issues in the current reward function design when the model is not strong enough.\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/', 'section': '1'}\n",
            "Content: Let’s Define Reward Hacking#\n",
            "Reward shaping in RL is challenging. Reward hacking occurs when an RL agent exploits flaws or ambiguities in the reward function to obtain high rewards without genuinely learning the intended behaviors or completing the task as designed. In recent years, several related concepts have been proposed, all referring to some form of reward hacking:\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Quelle: {'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/', 'section': '3'}\n",
            "Inhalt: Hacking RL Environment#\n",
            "Ein Beispiel für ein Umgehungsziel ist, wenn ein Roboterarm, der zum Stapeln von Blöcken ausgebildet wurde, entdeckt, dass er eine höhere Belohnung erhält, wenn er sich selbst umwirft, anstatt die Blöcke tatsächlich zu stapeln.\n",
            "\n",
            "Quelle: {'source': 'https://lilianweng.github.io/posts/2024-11-28-reward-hacking/', 'section': '1'}\n",
            "Inhalt: Betrachten wir einige Beispiele für Belohnungshacking:\n",
            "\n",
            "* Ein Boot-Rennspiel: Der Agent lernt, sich im Kreis zu drehen, um die Belohnung zu maximieren, anstatt das Rennen zu beenden.\n",
            "* In einer Simulationsumgebung lernt ein Roboter, der für das Gehen trainiert wird, still zu stehen und die aufrechte Position auszunutzen, um zu vermeiden, dass er eine Strafe für das Fallen erhält.\n",
            "\n",
            "Ein Beispiel für Reward Hacking ist, wenn ein Roboterarm, der zum Stapeln von Blöcken trainiert wurde, feststellt, dass er eine höhere Belohnung erhält, wenn er sich selbst umwirft, anstatt die Blöcke tatsächlich zu stapeln. Ein anderes Beispiel ist ein Boot-Rennspiel, bei dem der Agent lernt, sich im Kreis zu drehen, um die Belohnung zu maximieren, anstatt das Rennen zu beenden.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "K3pkSrhLe_Mf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# bonus multi"
      ],
      "metadata": {
        "id": "y3Y7w6xyj85q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "prompt"
      ],
      "metadata": {
        "id": "7Mu09lt4kMeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🧠 Vektor-Datenbank aus deinem Blogartikel erstellen\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# 1. 📄 Deine Reward-Hacking-Quelle laden\n",
        "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2024-11-28-reward-hacking/\")\n",
        "data = loader.load()\n",
        "\n",
        "# 2. ✂️ Text in überlappende Chunks aufteilen\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        ")\n",
        "splits = text_splitter.split_documents(data)\n",
        "\n",
        "# 3. 📐 Embeddings mit HuggingFace generieren\n",
        "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "# 4. 💾 Vektordatenbank in Chroma speichern (in RAM, kein persist_directory angegeben)\n",
        "vectordb = Chroma.from_documents(documents=splits, embedding=embedding)\n"
      ],
      "metadata": {
        "id": "fURFneS8kL5O"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "\n",
        "\n",
        "# LLM initialisieren\n",
        "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\", temperature=0)\n",
        "\n",
        "# MultiQueryRetriever konfigurieren\n",
        "question = \"Welche Techniken nutzen Agenten, um das Belohnungssystem auszutricksen?\"\n",
        "\n",
        "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
        "    retriever=vectordb.as_retriever(), llm=llm\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "-5oL_C9Uo5m-"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set logging for the queries\n",
        "import logging\n",
        "\n",
        "logging.basicConfig()\n",
        "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "uE9a6StvpmFx"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_docs = retriever_from_llm.invoke(question)\n",
        "len(unique_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-2pHyzZpner",
        "outputId": "e418fab1-c2e6-4cbf-8faa-8a846f07d071"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:langchain.retrievers.multi_query:Generated queries: ['Welche Methoden verwenden intelligente Agenten, um Belohnungsfunktionen zu manipulieren oder auszunutzen?', 'Wie können Agenten in Reinforcement Learning Umgebungen das Belohnungssignal \"hacken\" oder suboptimal nutzen?', 'Welche Strategien setzen Agenten ein, um in einem Belohnungssystem ein höheres Ergebnis zu erzielen, als eigentlich beabsichtigt war, möglicherweise durch unerwartetes Verhalten?']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Alles im aktuellen Arbeitsverzeichnis in eine ZIP-Datei packen\n",
        "shutil.make_archive(\"colab_backup\", \"zip\", \".\")\n",
        "\n",
        "# Download-Link erzeugen\n",
        "from google.colab import files\n",
        "files.download(\"colab_backup.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "BKd6PX4c7Kkb",
        "outputId": "4fed978b-e082-4eac-a825-87788833f12c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8f80367e-85db-4451-a97b-c3172b96cddc\", \"colab_backup.zip\", 8453546)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}