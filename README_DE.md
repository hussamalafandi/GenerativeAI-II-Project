# RAG-System: 2025 Aktienmarkt-Crash

Ein Retrieval-Augmented Generation (RAG) System, das Informationen Ã¼ber den Aktienmarkt-Crash von 2025 aus einem Wikipedia-Artikel abruft und kontextbasierte Antworten mit einem Sprachmodell generiert.

## âœ… Ziel

- Extrahierung von Inhalten aus einem Wikipedia-Artikel Ã¼ber den Aktienmarkt-Crash von 2025.
- Aufteilung des Inhalts in kleinere Abschnitte und Speicherung dieser in einer persistenten Vektordatenbank (ChromaDB).
- Implementierung eines Dialogflusses zur Beantwortung vordefinierter Fragen basierend auf dem abgerufenen Kontext.
- Verwendung des Sprachmodells `gemini-2.0-flash` zur Generierung von Antworten.

## ğŸ› ï¸ Technologien

- **LangChain** â€“ Retrieval- und QA-Pipeline.
- **ChromaDB** â€“ Persistente Dokumentenspeicherung.
- **Hugging Face Embeddings** â€“ Text-Embeddings mit `sentence-transformers/all-MiniLM-L6-v2`.
- **LangSmith** â€“ Logging und Tracing.
- **Langraph** â€“ Dialogflussverwaltung.
- **Google GenAI** â€“ Sprachmodell.
- **BeautifulSoup** â€“ Web-Scraping.

## âš¡ Umgebungsvariablen

Setzen Sie die folgenden Umgebungsvariablen:

- `LANGSMITH_API_KEY`
- `TAVILY_API_KEY`
- `GOOGLE_API_KEY`
- `HUGGINGFACE_API_KEY`

Sie kÃ¶nnen diese Variablen entweder direkt in der Umgebung setzen oder mithilfe der `userdata.get()` Methode in Google Colab.

## ğŸ“„ Datenextraktion und Verarbeitung

1. **Web-Scraping**  
   Der Inhalt wird aus dem Wikipedia-Artikel Ã¼ber den Aktienmarkt-Crash von 2025 mit **BeautifulSoup** extrahiert.

2. **Textaufteilung**  
   Der extrahierte Text wird in Abschnitte von 500 Zeichen mit einer Ãœberlappung von 100 Zeichen unterteilt, mithilfe von **LangChain**.

3. **Embedding**  
   Die Abschnitte werden mit **Hugging Face Embeddings** eingebettet, um den Text fÃ¼r die Suche zu reprÃ¤sentieren.

## ğŸ§  Dialogfluss

Das System verwendet **Langraph** zur Verwaltung des Dialogflusses, der zwei Hauptschritte umfasst:

1. **Abruf**  
   Abfragen von relevanten Abschnitten basierend auf der Nutzeranfrage.

2. **Generierung**  
   Generierung einer Antwort auf Basis des abgerufenen Kontexts unter Verwendung des Sprachmodells.

## ğŸ’¬ Fragenbeantwortung

Das System beantwortet vordefinierte Fragen zum Aktienmarkt-Crash von 2025. FÃ¼r jede Frage wird der Kontext abgerufen und eine Antwort generiert.

## ğŸ“ Protokollierung

Die Interaktionen mit dem System werden mit **LangSmith** protokolliert, um das Tracking und Monitoring zu ermÃ¶glichen. Jede Interaktion wird mit Metadaten zur besseren Nachverfolgbarkeit aufgezeichnet.

## ğŸ“Š Testen

- Das System wurde mit mindestens fÃ¼nf sinnvollen Fragen getestet, um die Wirksamkeit der Dokumentabrufstrategie zu Ã¼berprÃ¼fen.
- Jede Frage wird validiert, indem der abgerufene Kontext und die generierte Antwort Ã¼berprÃ¼ft werden.

## ğŸš€ ZukÃ¼nftige Arbeiten

- Implementierung von Metadatenfilterung zur Verbesserung des Abrufs.
- ErmÃ¶glichung der Mehrfachabfrageverarbeitung zur effektiveren Bearbeitung komplexer Fragen.
- Verbesserung der Fehlerbehandlung und Implementierung eines ausgeklÃ¼gelten Loggings und Monitorings.

## ğŸ“„ Lizenz

Dieses Projekt ist unter der MIT-Lizenz lizenziert.
