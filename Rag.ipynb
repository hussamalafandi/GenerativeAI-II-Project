{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a23b737",
   "metadata": {},
   "source": [
    "## Build a RAG \n",
    "\n",
    "Dieses Skript implementiert ein Retrieval-Augented-Generation System mit LangSmith, um die Leistung zu verfolgen und Fehler zu analysieren.\n",
    "AuÃŸerdem wurde die Funktion des dynamischen Ã„nderens von Prompts implementiert, um die AntwortqualitÃ¤t zu optimieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad4effc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "C:\\Users\\hshakademie3\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langsmith.run_helpers import traceable   \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33adc9a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_Environ' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m load_dotenv()\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…Ù† Ø¨ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m google_api_key = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGOOGLE_API_KEY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m langchain_api_key = os.environ(\u001b[33m\"\u001b[39m\u001b[33mLANGCHAIN_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù…ÙØªØ§Ø­ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ­Ù…ÙŠÙ„Ù‡ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: '_Environ' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc2576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” \n",
    "\n",
    "\n",
    "\n",
    "# ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù„Ù…ÙƒØªØ¨Ø© LangSmith\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"GOOGLE_API_KEY\"\n",
    "os.environ[\"HF_TOKEN\"] = \"HF_TOKEN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ec6d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://www.spiegel.de/wirtschaft/unternehmen/tesla-entlaesst-ueber-10000-mitarbeiter-wegen-absatzproblemen-a-xyz\"\n",
    "loader = WebBaseLoader(url)\n",
    "document = loader.load()[0].page_content.strip().replace(\"\\n\", \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45dda681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ù…Ù‚Ø§Ø·Ø¹ ØµØºÙŠØ±Ø© sinnvoll chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "docs = splitter.create_documents([document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1783f42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hshakademie3\\AppData\\Local\\Temp\\ipykernel_19216\\325043896.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "C:\\Users\\hshakademie3\\AppData\\Local\\Temp\\ipykernel_19216\\325043896.py:11: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    }
   ],
   "source": [
    "persist_directory = \"chroma_db_rag\"\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "embedding.embed_query('hi')\n",
    "\n",
    "db = Chroma.from_documents(documents=docs,\n",
    "                           embedding=embedding,\n",
    "                           persist_directory=persist_directory)\n",
    "retriever = db.as_retriever()\n",
    "db.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30c7a1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hshakademie3\\AppData\\Local\\Temp\\ipykernel_19216\\1046491335.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfeda518",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.2)\n",
    "rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "632564ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_documents_by_metadata(metadata_key, metadata_value):\n",
    "    # ÙÙ„ØªØ±Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙŠØªØ§Ø¯Ø§ØªØ§\n",
    "    filtered_docs = []\n",
    "    for doc in docs:\n",
    "        if doc.metadata.get(metadata_key) == metadata_value:\n",
    "            filtered_docs.append(doc)\n",
    "    return filtered_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e81236cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_query_retrieval(queries):\n",
    "    # Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©\n",
    "    answers = []\n",
    "    for query in queries:\n",
    "        result = rag_chain.invoke({\"question\": query})\n",
    "        answers.append(result['answer'])\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05516c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def answer_question(frage):\n",
    "    return rag_chain.invoke({\"question\": frage})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1df1422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fragen = [\n",
    "    \"Warum hat Tesla im Jahr 2024 so viele Mitarbeiter entlassen?\",\n",
    "    \"Was ist der Grund fÃ¼r den UmsatzrÃ¼ckgang von Tesla?\",\n",
    "    \"Wann begann der Stellenabbau bei Tesla?\",\n",
    "    \"Warum hat Tesla Mitarbeiter entlassen? Was waren die Ursachen?\",\n",
    "    \"Welches Modell von Tesla hatte den grÃ¶ÃŸten RÃ¼ckgang in den Verkaufszahlen?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89255467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variieren Sie die Prompts und analysieren Sie deren Auswirkungen\n",
    "prompts = [\n",
    "    \"Was waren die GrÃ¼nde fÃ¼r die Entlassungen bei Tesla im Jahr 2024?\",\n",
    "    \"Warum hat Tesla viele Mitarbeiter in 2024 entlassen? ErklÃ¤ren Sie den Zusammenhang.\",\n",
    "    \"Gibt es spezifische Ursachen fÃ¼r den RÃ¼ckgang des Tesla-Umsatzes 2024?\",\n",
    "    \"Welche Faktoren haben zu den Entlassungen bei Tesla gefÃ¼hrt?\",\n",
    "    \"Warum ist der Umsatz von Tesla im Jahr 2024 gefallen?\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b943f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ Google API Key: GOOGLE_API_KEY\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"ğŸ”‘ Google API Key:\", os.environ[\"GOOGLE_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90653f10",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multi_query_retrieval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m multi_query_results = \u001b[43mmulti_query_retrieval\u001b[49m(prompts)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mğŸ”„ Ergebnisse der Multi-Query Retrieval:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m multi_query_results:\n",
      "\u001b[31mNameError\u001b[39m: name 'multi_query_retrieval' is not defined"
     ]
    }
   ],
   "source": [
    "multi_query_results = multi_query_retrieval(prompts)\n",
    "print(\"\\nğŸ”„ Ergebnisse der Multi-Query Retrieval:\")\n",
    "for result in multi_query_results:\n",
    "    print(\"\\nğŸ’¡ Antwort:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1722b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frage in fragen:\n",
    "    print(\"\\nâ“ Frage:\", frage)\n",
    "    result = answer_question(frage)\n",
    "    print(\"\\nğŸ’¡ Antwort:\", result['answer'])\n",
    "    print(\"ğŸ“š Quelle:\", result['source_documents'][0].metadata.get('source', 'Unbekannt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d03235",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ“¦ 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª\n",
    "# -----------------------------\n",
    "# ğŸ“° 3. ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©\n",
    "# -----------------------------\n",
    "# ØªØ­Ù…ÙŠÙ„ Ù…Ù‚Ø§Ù„ Ø­Ø¯ÙŠØ« Ø¨Ø¹Ø¯ Ø£ØºØ³Ø·Ø³ 2024\n",
    "# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ù…Ù‚Ø§Ø·Ø¹ ØµØºÙŠØ±Ø© sinnvoll chunks\n",
    "# -----------------------------\n",
    "# ğŸ’¾ 4. Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øªå‘é‡ÙŠØ© - Chroma\n",
    "# -----------------------------\n",
    "# ğŸ§  5. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ù„Ø­ÙˆØ§Ø±\n",
    "# -----------------------------\n",
    "# ğŸ¤– 6. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù€ RAG Chain\n",
    "# -----------------------------\n",
    "# ğŸ” 7. ÙÙ„ØªØ±Ø© Ø§Ù„Ù…ÙŠØªØ§Ø¯Ø§ØªØ§ - Bonus\n",
    "# -----------------------------\n",
    "# ğŸ”„ 8. Multi-Query Retrieval - Bonus\n",
    "# -----------------------------\n",
    "# ğŸ’¬ 9. Ø¯Ø§Ù„Ø© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ø¹ LangSmith\n",
    "# -----------------------------\n",
    "# ğŸ§ª 10. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù… - Beispiele\n",
    "# -----------------------------\n",
    "# Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹ ØªØºÙŠÙŠØ± Ø§Ù„Ù€ Prompts\n",
    "# Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©\n",
    "# Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙˆØ§Ø­Ø¯"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
